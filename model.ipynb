{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1967b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic2 = pd.read_csv('titanic_df.csv')\n",
    "titanic2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84809b63",
   "metadata": {},
   "source": [
    "##  Question 1 - Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c8687",
   "metadata": {},
   "source": [
    "- What is your baseline prediction? \n",
    "\n",
    "- What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). \n",
    "\n",
    "- When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280222fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16daf919",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = prepare.prep_titanic_data(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a5e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71498e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age = df.age.fillna(df.age.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00eab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['pclass', 'embarked', 'embarked_encode', 'passenger_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, ['sex', 'class', 'embark_town'], drop_first=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split(df, stratify_by='survived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9415bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14377e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = titanic[['pclass', 'fare']]\n",
    "# y = titanic.survived\n",
    "\n",
    "# X_train_and_validate, X_test, y_train_and_validate, y_test = train_test_split(X, y, random_state=123, test_size=.3)\n",
    "# X_train, X_validate, y_train, y_validate = train_test_split(X_train_and_validate, y_train_and_validate, random_state=123, test_size=.2)\n",
    "\n",
    "# print(\"train: \", X_train.shape, \", validate: \", X_validate.shape, \", test: \", X_test.shape)\n",
    "# print(\"train: \", y_train.shape, \", validate: \", y_validate.shape, \", test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2a29c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline = y_train.mode()\n",
    "\n",
    "\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3459fe",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eeab81",
   "metadata": {},
   "source": [
    "- Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4692fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(tree, feature_names=X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = tree.predict(X_train)\n",
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree, feature_names=X_train.columns, class_names=['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4697c",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b45c314",
   "metadata": {},
   "source": [
    "- Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061627db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusematrix\n",
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea38304",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_train, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9de2e",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b602381a",
   "metadata": {},
   "source": [
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c408f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d01a4ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db251bc8",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94f43d",
   "metadata": {},
   "source": [
    "- Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701485d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_predictions).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cases = TN + FP\n",
    "positive_cases = FN + TP\n",
    "print(f\"Negative Cases: {negative_cases}\")\n",
    "print(f\"Positive Cases: {positive_cases}\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e891cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9b79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da203870",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1335802",
   "metadata": {},
   "source": [
    "Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb47eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\" Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2c9fc",
   "metadata": {},
   "source": [
    "## Question 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27eecae",
   "metadata": {},
   "source": [
    "- Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7892a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth of 15+ produces the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae8d05",
   "metadata": {},
   "source": [
    "## Question 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd96f8",
   "metadata": {},
   "source": [
    "- Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.score(X_validate, y_validate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b029c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#better accurace to guess not survived in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(1, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05013994",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.max_depth, df.train_accuracy, marker = 'o')\n",
    "plt.plot(df.max_depth, df.validate_accuracy, marker = 'o')\n",
    "plt.title('Overfitting Occurs at Higher Values for Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc49c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2783e0",
   "metadata": {},
   "source": [
    " ## Work through these same exercises using the Telco dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569ed49",
   "metadata": {},
   "source": [
    "- What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). \n",
    "- When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco = pd.read_csv('telco.csv')\n",
    "telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7515cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "telco.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78c805",
   "metadata": {},
   "source": [
    "## Random forest Excercizes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f3907",
   "metadata": {},
   "source": [
    "- Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962c48c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee73a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a69379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "df = prepare.prep_titanic_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age = df.age.fillna(df.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['pclass', 'embarked', 'embarked_encode', 'passenger_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, ['sex', 'class', 'embark_town'], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split(df, stratify_by='survived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042954d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f770be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_validate.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8189510",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline prediction: {baseline[0]}\")\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1 = RandomForestClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "forest1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = forest1.predict(X_train)\n",
    "\n",
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of depth 3\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3113da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_predictions, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train,y_predictions).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37087d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 11):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = forest.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42faf4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda48456",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cfdf5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.set_index('max_depth').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa2ba6d",
   "metadata": {},
   "source": [
    "- Increasing min_samples_per_leaf, decreasing max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271aca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    # Make the model\n",
    "    depth = max_depth - i\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a956bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('max_depth')[['train_accuracy', 'validate_accuracy','difference']].plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327be63b",
   "metadata": {},
   "source": [
    "- What about a fixed depth and increasing min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "\n",
    "for i in range(2, 50):\n",
    "    # Make the model\n",
    "    depth = 6\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('min_samples_per_leaf')[['train_accuracy', 'validate_accuracy', 'difference']].plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,50,5))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029fcb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b5b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validate, test = train_validate_test_split(titanic, target='survived', seed=123)\n",
    "\n",
    "# # Explore your data here. \n",
    "\n",
    "# # create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "# X_train = train.drop(columns=['survived'])\n",
    "# y_train = train.survived\n",
    "\n",
    "# X_validate = validate.drop(columns=['survived'])\n",
    "# y_validate = validate.survived\n",
    "\n",
    "# X_test = test.drop(columns=['survived'])\n",
    "# y_test = test.survived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efa950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad215449",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=3, \n",
    "                            random_state=123)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba255d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391cca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b991c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565408b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f306e8",
   "metadata": {},
   "source": [
    "- Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c381d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fa740",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d81e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d90d12",
   "metadata": {},
   "source": [
    "- Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1956550",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1 = RandomForestClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "forest1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = forest1.predict(X_train)\n",
    "\n",
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_predictions).ravel()\n",
    "\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af880d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c605f",
   "metadata": {},
   "source": [
    "- Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452299b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6, 15):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\" Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bfb32",
   "metadata": {},
   "source": [
    "- What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(1, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea127ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.max_depth, df.train_accuracy, marker = 'o')\n",
    "plt.plot(df.max_depth, df.validate_accuracy, marker = 'o')\n",
    "plt.title('Overfitting Occurs at Higher Values for Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d2a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1acb231",
   "metadata": {},
   "source": [
    "# KNN exercizes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84a155",
   "metadata": {},
   "source": [
    "#### - Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768e588d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cccc33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  embarked_encode  \n",
       "0        S  Third  Southampton      0                3  \n",
       "1        C  First    Cherbourg      0                0  \n",
       "2        S  Third  Southampton      1                3  \n",
       "3        S  First  Southampton      0                3  \n",
       "4        S  Third  Southampton      1                3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prepare.prep_titanic_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f91096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age = df.age.fillna(df.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cafe246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['embarked', 'embarked_encode', 'passenger_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1569c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Other</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500      0         1   \n",
       "1         1       1  38.0      1      0  71.2833      0         0   \n",
       "2         1       3  26.0      0      0   7.9250      1         0   \n",
       "3         1       1  35.0      1      0  53.1000      0         0   \n",
       "4         0       3  35.0      0      0   8.0500      1         1   \n",
       "\n",
       "   class_Second  class_Third  embark_town_Other  embark_town_Queenstown  \\\n",
       "0             0            1                  0                       0   \n",
       "1             0            0                  0                       0   \n",
       "2             0            1                  0                       0   \n",
       "3             0            0                  0                       0   \n",
       "4             0            1                  0                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, ['sex', 'class', 'embark_town'], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1efa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split(df, stratify_by='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be31e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25874123",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=1, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb48b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn1.predict(X_train)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7811351",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a45aab",
   "metadata": {},
   "source": [
    "### - Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce113c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37338043",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97593c",
   "metadata": {},
   "source": [
    "### - Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e552d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_pred).ravel()\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 307\n",
    "FP = 0\n",
    "FN = 2\n",
    "TN = 189\n",
    "\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9dc1b",
   "metadata": {},
   "source": [
    "### - Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn10 = KNeighborsClassifier(n_neighbors=10, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e62d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn10.predict(X_train)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ead060",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 273\n",
    "FP = 34\n",
    "FN = 95\n",
    "TN = 96\n",
    "\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6b8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ff100c",
   "metadata": {},
   "source": [
    "### - Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a017062",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn20 = KNeighborsClassifier(n_neighbors=20, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f0d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn20.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be901a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn20.predict(X_train)\n",
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510618a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c32dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 270\n",
    "FP = 37\n",
    "FN = 103\n",
    "TN = 88\n",
    "\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9c366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d06bd8",
   "metadata": {},
   "source": [
    "### - What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44734d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks like this one is better becasue of the accuracy at 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b60ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn10.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa5224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn20.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22806933",
   "metadata": {},
   "source": [
    "### -Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c87a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN (k=1) classifier on validate set: {:.2f}'\n",
    "     .format(knn1.score(X_validate, y_validate)))\n",
    "\n",
    "print('Accuracy of KNN (k=10) classifier on validate set: {:.2f}'\n",
    "     .format(knn10.score(X_validate, y_validate)))\n",
    "\n",
    "print('Accuracy of KNN (k=20) classifier on validate set: {:.2f}'\n",
    "     .format(knn20.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ce73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks like 10 or 20 is the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c484cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "train_scores = []\n",
    "validate_scores = []\n",
    "test_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    validate_scores.append(knn.score(X_validate, y_validate))\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(k_range, train_scores, label='Train')\n",
    "plt.plot(k_range, validate_scores, label='Validate')\n",
    "plt.plot(k_range, test_scores, label='Test')\n",
    "plt.legend()\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46571db7",
   "metadata": {},
   "source": [
    " ## Once you have completed work on the titanic dataset, try building some knn models with your telco data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169cefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_telco_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6509af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87be7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d881c10b",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218a673",
   "metadata": {},
   "source": [
    "- Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b266410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6eb223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Other</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch     fare  alone  sex_male  \\\n",
       "0           0       3  22.000000      1      0   7.2500      0         1   \n",
       "1           1       1  38.000000      1      0  71.2833      0         0   \n",
       "2           1       3  26.000000      0      0   7.9250      1         0   \n",
       "3           1       1  35.000000      1      0  53.1000      0         0   \n",
       "4           0       3  35.000000      0      0   8.0500      1         1   \n",
       "..        ...     ...        ...    ...    ...      ...    ...       ...   \n",
       "886         0       2  27.000000      0      0  13.0000      1         1   \n",
       "887         1       1  19.000000      0      0  30.0000      1         0   \n",
       "888         0       3  29.699118      1      2  23.4500      0         0   \n",
       "889         1       1  26.000000      0      0  30.0000      1         1   \n",
       "890         0       3  32.000000      0      0   7.7500      1         1   \n",
       "\n",
       "     class_Second  class_Third  embark_town_Other  embark_town_Queenstown  \\\n",
       "0               0            1                  0                       0   \n",
       "1               0            0                  0                       0   \n",
       "2               0            1                  0                       0   \n",
       "3               0            0                  0                       0   \n",
       "4               0            1                  0                       0   \n",
       "..            ...          ...                ...                     ...   \n",
       "886             1            0                  0                       0   \n",
       "887             0            0                  0                       0   \n",
       "888             0            1                  0                       0   \n",
       "889             0            0                  0                       0   \n",
       "890             0            1                  0                       1   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  \n",
       "..                       ...  \n",
       "886                        1  \n",
       "887                        1  \n",
       "888                        1  \n",
       "889                        0  \n",
       "890                        0  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8323fd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Other</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  sex_male  \\\n",
       "583         0       1  36.000000      0      0   40.1250      1         1   \n",
       "165         1       3   9.000000      0      2   20.5250      0         1   \n",
       "50          0       3   7.000000      4      1   39.6875      0         1   \n",
       "259         1       2  50.000000      0      1   26.0000      0         0   \n",
       "306         1       1  29.699118      0      0  110.8833      1         0   \n",
       "..        ...     ...        ...    ...    ...       ...    ...       ...   \n",
       "313         0       3  28.000000      0      0    7.8958      1         1   \n",
       "636         0       3  32.000000      0      0    7.9250      1         1   \n",
       "222         0       3  51.000000      0      0    8.0500      1         1   \n",
       "485         0       3  29.699118      3      1   25.4667      0         0   \n",
       "744         1       3  31.000000      0      0    7.9250      1         1   \n",
       "\n",
       "     class_Second  class_Third  embark_town_Other  embark_town_Queenstown  \\\n",
       "583             0            0                  0                       0   \n",
       "165             0            1                  0                       0   \n",
       "50              0            1                  0                       0   \n",
       "259             1            0                  0                       0   \n",
       "306             0            0                  0                       0   \n",
       "..            ...          ...                ...                     ...   \n",
       "313             0            1                  0                       0   \n",
       "636             0            1                  0                       0   \n",
       "222             0            1                  0                       0   \n",
       "485             0            1                  0                       0   \n",
       "744             0            1                  0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "583                        0  \n",
       "165                        1  \n",
       "50                         1  \n",
       "259                        1  \n",
       "306                        0  \n",
       "..                       ...  \n",
       "313                        1  \n",
       "636                        1  \n",
       "222                        1  \n",
       "485                        1  \n",
       "744                        1  \n",
       "\n",
       "[498 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = prepare.split(df, stratify_by='survived')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe67db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e126b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51cc7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\", \"fare\", \"pclass\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\", \"fare\", \"pclass\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\", \"fare\", \"pclass\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6364bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1 , random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93714a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b353d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logit.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68888046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8418bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fba280fe",
   "metadata": {},
   "source": [
    "- Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6edcab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\", \"fare\", \"pclass\", \"sex_male\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\", \"fare\", \"pclass\", \"sex_male\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\", \"fare\", \"pclass\", \"sex_male\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a68d4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2 = LogisticRegression(C=1 , random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ad8be92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16cf602d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dcbdfa",
   "metadata": {},
   "source": [
    "- Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a934f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\", \"fare\", \"sex_male\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\", \"fare\", \"sex_male\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\", \"fare\", \"sex_male\"])\n",
    "y_test = test.survived\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6127cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit3 = LogisticRegression(C=1 , random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "695c7b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ac60c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.72\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a14765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9161c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "906682b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\", \"fare\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\", \"fare\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\", \"fare\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e9eefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit4 = LogisticRegression(C=1 , random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd4eb4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcdfbeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit4.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a7b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b2b58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18758c13",
   "metadata": {},
   "source": [
    "- Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04c08de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_validate = logit.predict(X_validate)\n",
    "y_pred_validate2 = logit3.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd951041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: solver = lbfgs, c = 1\n",
      "Accuracy: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       132\n",
      "           1       0.68      0.51      0.58        82\n",
      "\n",
      "    accuracy                           0.72       214\n",
      "   macro avg       0.71      0.68      0.69       214\n",
      "weighted avg       0.71      0.72      0.71       214\n",
      "\n",
      "Model 2: solver = lbfgs, c = 1\n",
      "Accuracy: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       132\n",
      "           1       0.68      0.51      0.58        82\n",
      "\n",
      "    accuracy                           0.72       214\n",
      "   macro avg       0.71      0.68      0.69       214\n",
      "weighted avg       0.71      0.72      0.71       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1: solver = lbfgs, c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit.score(X_validate, y_validate)))\n",
    "\n",
    "print(classification_report(y_validate, y_pred_validate))\n",
    "\n",
    "print(\"Model 2: solver = lbfgs, c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit3.score(X_validate, y_validate)))\n",
    "\n",
    "print(classification_report(y_validate, y_pred_validate2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abd82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c1a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "219f885b",
   "metadata": {},
   "source": [
    "- Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3716259",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "y_pred = logit1.predict(X_validate[features])\n",
    "\n",
    "print('Logit1 model using age, pclass, fare, and is_female as the features')\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit2.predict(X_validate)\n",
    "\n",
    "print(\"Logit2 model using all features and all model defaults\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit3.predict(X_validate)\n",
    "\n",
    "print(\"Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d33768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
